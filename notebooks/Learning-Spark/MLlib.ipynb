{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imad/anaconda3/envs/spark_test/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/imad/anaconda3/envs/spark_test/lib/python3.8/site-packages/pyspark/sql/context.py:75: DeprecationWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://imads-mbp.attlocal.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ML in Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7feea8cb0130>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('ML in Spark').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport-codes-na.txt      feature-importance.csv    sf-fire-calls.csv\n",
      "departuredelays.csv       loan-risks.snappy.parquet \u001b[1m\u001b[36mtest-df.parquet\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path('data')\n",
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7146"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (spark\n",
    "      .read\n",
    "      .parquet((DATA_PATH / 'sf-airbnb-clean.parquet').as_posix()))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost',\n",
       " 'cancellation_policy',\n",
       " 'instant_bookable',\n",
       " 'host_total_listings_count',\n",
       " 'neighbourhood_cleansed',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'bed_type',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'price',\n",
       " 'bedrooms_na',\n",
       " 'bathrooms_na',\n",
       " 'beds_na',\n",
       " 'review_scores_rating_na',\n",
       " 'review_scores_accuracy_na',\n",
       " 'review_scores_cleanliness_na',\n",
       " 'review_scores_checkin_na',\n",
       " 'review_scores_communication_na',\n",
       " 'review_scores_location_na',\n",
       " 'review_scores_value_na']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------+--------+---------+-----------------+-----+\n",
      "|neighbourhood_cleansed|      room_type|bedrooms|bathrooms|number_of_reviews|price|\n",
      "+----------------------+---------------+--------+---------+-----------------+-----+\n",
      "|      Western Addition|Entire home/apt|     1.0|      1.0|            180.0|170.0|\n",
      "|        Bernal Heights|Entire home/apt|     2.0|      1.0|            111.0|235.0|\n",
      "|        Haight Ashbury|   Private room|     1.0|      4.0|             17.0| 65.0|\n",
      "|        Haight Ashbury|   Private room|     1.0|      4.0|              8.0| 65.0|\n",
      "|      Western Addition|Entire home/apt|     2.0|      1.5|             27.0|785.0|\n",
      "+----------------------+---------------+--------+---------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"neighbourhood_cleansed\", \"room_type\", \"bedrooms\", \"bathrooms\",\n",
    "\"number_of_reviews\", \"price\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5780, 1366)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = df.randomSplit([.8, .2], seed=42)\n",
    "train_df.count(), test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('host_is_superhost', 'string'),\n",
       " ('cancellation_policy', 'string'),\n",
       " ('instant_bookable', 'string'),\n",
       " ('host_total_listings_count', 'double'),\n",
       " ('neighbourhood_cleansed', 'string'),\n",
       " ('latitude', 'double'),\n",
       " ('longitude', 'double'),\n",
       " ('property_type', 'string'),\n",
       " ('room_type', 'string'),\n",
       " ('accommodates', 'double'),\n",
       " ('bathrooms', 'double'),\n",
       " ('bedrooms', 'double'),\n",
       " ('beds', 'double'),\n",
       " ('bed_type', 'string'),\n",
       " ('minimum_nights', 'double'),\n",
       " ('number_of_reviews', 'double'),\n",
       " ('review_scores_rating', 'double'),\n",
       " ('review_scores_accuracy', 'double'),\n",
       " ('review_scores_cleanliness', 'double'),\n",
       " ('review_scores_checkin', 'double'),\n",
       " ('review_scores_communication', 'double'),\n",
       " ('review_scores_location', 'double'),\n",
       " ('review_scores_value', 'double'),\n",
       " ('price', 'double'),\n",
       " ('bedrooms_na', 'double'),\n",
       " ('bathrooms_na', 'double'),\n",
       " ('beds_na', 'double'),\n",
       " ('review_scores_rating_na', 'double'),\n",
       " ('review_scores_accuracy_na', 'double'),\n",
       " ('review_scores_cleanliness_na', 'double'),\n",
       " ('review_scores_checkin_na', 'double'),\n",
       " ('review_scores_communication_na', 'double'),\n",
       " ('review_scores_location_na', 'double'),\n",
       " ('review_scores_value_na', 'double')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical fields:\n",
      "['host_is_superhost', 'cancellation_policy', 'instant_bookable', 'neighbourhood_cleansed', 'property_type', 'room_type', 'bed_type']\n",
      "\n",
      "Numerical fields:\n",
      "['host_total_listings_count', 'latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'minimum_nights', 'number_of_reviews', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'bedrooms_na', 'bathrooms_na', 'beds_na', 'review_scores_rating_na', 'review_scores_accuracy_na', 'review_scores_cleanliness_na', 'review_scores_checkin_na', 'review_scores_communication_na', 'review_scores_location_na', 'review_scores_value_na']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [field for (field, dtype) in train_df.dtypes if dtype == 'string']\n",
    "num_cols = [field for (field, dtype) in train_df.dtypes if dtype != 'string' and field != 'price']\n",
    "print(f'Categorical fields:\\n{cat_cols}\\n')\n",
    "print(f'Numerical fields:\\n{num_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_cols = [col + '_indexed' for col in cat_cols]\n",
    "encoded_cols = [col + '_encoded' for col in cat_cols]\n",
    "\n",
    "indexer = (StringIndexer()\n",
    "           .setInputCols(cat_cols)\n",
    "           .setOutputCols(indexed_cols)\n",
    "           .setHandleInvalid('skip'))\n",
    "\n",
    "ohe = (OneHotEncoder()\n",
    "       .setInputCols(indexed_cols)\n",
    "       .setOutputCols(encoded_cols))\n",
    "\n",
    "vector_assembler = (VectorAssembler()\n",
    "                    .setInputCols(encoded_cols)\n",
    "                    .setOutputCol('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='features', labelCol='price')\n",
    "lr_pipeline = Pipeline(stages=[indexer, ohe, vector_assembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline_model = lr_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|            features|price|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|(72,[0,3,6,22,43,...| 85.0|237.64086207083028|\n",
      "|(72,[0,3,6,22,43,...| 45.0| 73.42133044353568|\n",
      "|(72,[0,3,6,22,43,...| 70.0| 73.42133044353568|\n",
      "|(72,[0,3,6,12,42,...|128.0|11.787699210826759|\n",
      "|(72,[0,3,6,12,43,...|159.0|132.70651723063725|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_df = lr_pipeline_model.transform(test_df)\n",
    "pred_df.select('features', 'price', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228.26400958005436"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_eval = RegressionEvaluator(predictionCol='prediction', labelCol='price', metricName='rmse')\n",
    "reg_eval.evaluate(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1007840913115724"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_eval.setMetricName('r2').evaluate(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline_model.write().overwrite().save('linear_reg_pip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline_model = PipelineModel.load('linear_reg_pip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1007840913115724"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_eval.setMetricName('r2').evaluate(lr_pipeline_model.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_cols = [col + '_indexed' for col in cat_cols]\n",
    "\n",
    "indexer = (StringIndexer()\n",
    "           .setInputCols(cat_cols)\n",
    "           .setOutputCols(indexed_cols)\n",
    "           .setHandleInvalid('skip'))\n",
    "\n",
    "vector_assembler = (VectorAssembler()\n",
    "                    .setInputCols(indexed_cols)\n",
    "                    .setOutputCol('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol='features', labelCol='price', maxBins=40, seed=42)\n",
    "rf_pipeline = Pipeline(stages=[indexer, vector_assembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline_model = rf_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|            features|price|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|(7,[1,3,4],[2.0,1...| 85.0| 274.3913584878296|\n",
      "|[0.0,2.0,0.0,15.0...| 45.0| 99.25241040164991|\n",
      "|[0.0,2.0,0.0,15.0...| 70.0| 99.25241040164991|\n",
      "|(7,[1,3,5],[2.0,5...|128.0|111.09933784188517|\n",
      "|[0.0,2.0,0.0,5.0,...|159.0|112.73108938398084|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_df = rf_pipeline_model.transform(test_df)\n",
    "pred_df.select('features', 'price', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232.41858310308692"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_eval = RegressionEvaluator(predictionCol='prediction', labelCol='price', metricName='rmse')\n",
    "reg_eval.evaluate(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06775342383805139"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_eval.setMetricName('r2').evaluate(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imad/anaconda3/envs/spark_test/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancellation_policy_indexed</td>\n",
       "      <td>0.258472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>room_type_indexed</td>\n",
       "      <td>0.243863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neighbourhood_cleansed_indexed</td>\n",
       "      <td>0.234067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>property_type_indexed</td>\n",
       "      <td>0.191982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instant_bookable_indexed</td>\n",
       "      <td>0.043699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>host_is_superhost_indexed</td>\n",
       "      <td>0.026677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bed_type_indexed</td>\n",
       "      <td>0.001241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature  importance\n",
       "1     cancellation_policy_indexed    0.258472\n",
       "5               room_type_indexed    0.243863\n",
       "3  neighbourhood_cleansed_indexed    0.234067\n",
       "4           property_type_indexed    0.191982\n",
       "2        instant_bookable_indexed    0.043699\n",
       "0       host_is_superhost_indexed    0.026677\n",
       "6                bed_type_indexed    0.001241"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(\n",
    "    list(\n",
    "        zip(rf_pipeline_model.stages[-2].getInputCols(), rf_pipeline_model.stages[-1].featureImportances))\n",
    "    , columns=['feature', 'importance'])\n",
    " .sort_values(by='importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imad/anaconda3/envs/spark_test/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "indexed_cols = [col + '_indexed' for col in cat_cols]\n",
    "\n",
    "indexer = (StringIndexer()\n",
    "           .setInputCols(cat_cols)\n",
    "           .setOutputCols(indexed_cols)\n",
    "           .setHandleInvalid('skip'))\n",
    "\n",
    "vector_assembler = (VectorAssembler()\n",
    "                    .setInputCols(indexed_cols)\n",
    "                    .setOutputCol('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol='features', labelCol='price', maxBins=40, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline(stages=[indexer, vector_assembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol='price', predictionCol='prediction', metricName='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = (ParamGridBuilder()\n",
    "              .addGrid(rf.maxDepth, [2, 4, 6])\n",
    "              .addGrid(rf.numTrees, [10, 100])\n",
    "              .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = (CrossValidator()\n",
    "      .setEstimator(rf_pipeline)\n",
    "      .setEvaluator(evaluator)\n",
    "      .setEstimatorParamMaps(param_grid)\n",
    "      .setNumFolds(3)\n",
    "      .setSeed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 997 ms, sys: 232 ms, total: 1.23 s\n",
      "Wall time: 24.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CrossValidatorModel_01b95d4b1c9b"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = (CrossValidator()\n",
    "      .setEstimator(rf_pipeline)\n",
    "      .setEvaluator(evaluator)\n",
    "      .setEstimatorParamMaps(param_grid)\n",
    "      .setNumFolds(3)\n",
    "      .setParallelism(4)\n",
    "      .setSeed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 392 ms, total: 1.68 s\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CrossValidatorModel_4922b911ac59"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = (CrossValidator()\n",
    "      .setEstimator(rf)\n",
    "      .setEvaluator(evaluator)\n",
    "      .setEstimatorParamMaps(param_grid)\n",
    "      .setParallelism(4)\n",
    "      .setNumFolds(3)\n",
    "      .setSeed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline(stages=[indexer, vector_assembler, cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 695 ms, sys: 189 ms, total: 885 ms\n",
      "Wall time: 12.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PipelineModel_13720f487a10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rf_pipeline.fit(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
